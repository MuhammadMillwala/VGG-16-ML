{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMwtQ8tbLFb6",
        "outputId": "323984b0-1b45-4346-f488-d63127f723fb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "80fEmJJqynuO"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir ='/content/drive/MyDrive/ML_Project/fruits-360/fruits-360/Test'\n",
        "test_transform = transforms.Compose([transforms.Resize(200),transforms.CenterCrop(224),transforms.ToTensor()])\n",
        "test_data = datasets.ImageFolder(data_dir, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=16,shuffle=False,num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "H_zNV21hyt0s"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir ='/content/drive/MyDrive/ML_Project/fruits-360/fruits-360/Training'\n",
        "train_transform = transforms.Compose([transforms.Resize(200) , transforms.CenterCrop(224), transforms.ToTensor()])\n",
        "train_data = datasets.ImageFolder(data_dir,transform=train_transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_data,batch_size=16,shuffle=False,num_workers=2)"
      ],
      "metadata": {
        "id": "6rIuRWStJajz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = train_data.classes"
      ],
      "metadata": {
        "id": "XI3eJIyXzgvb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 500   # Number of samples in each batch\n",
        "epoch_num = 4      # Number of epochs to train the network\n",
        "lr = 0.0005        # Learning rate\n"
      ],
      "metadata": {
        "id": "K2Zp-4SOVwSz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VGG16 Architecture Build \n",
        "\n",
        "\n",
        "\n",
        "class VGG_architecture(nn.Module):\n",
        "  def __init__(self,in_channels=3,num_classes=1000):\n",
        "    super(VGG_architecture,self).__init__()\n",
        "    self.layer1 = vgg_conv_block([in_channels,64], [64,64], [3,3], [1,1], 2, 2)\n",
        "    self.layer2 = vgg_conv_block([64,128], [128,128], [3,3], [1,1], 2, 2)\n",
        "    self.layer3 = vgg_conv_block([128,256,256], [256,256,256], [3,3,3], [1,1,1], 2, 2)\n",
        "    self.layer4 = vgg_conv_block([256,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
        "    self.layer5 = vgg_conv_block([512,512,512], [512,512,512], [3,3,3], [1,1,1], 2, 2)\n",
        "\n",
        "    self.layer1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "    self.layer1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    self.layer2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "    self.layer2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "    \n",
        "    self.layer3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "    self.layer3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.layer3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    self.layer4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "    self.layer4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.layer4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "    self.layer5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.layer5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.layer5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    # max pooling (kernel_size, stride)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    # fully conected layers:\n",
        "    self.fully_connected6 = nn.Linear(7*7*512, 4096)\n",
        "    self.fully_connected7 = nn.Linear(4096, 4096)\n",
        "    self.fully_connected8 = nn.Linear(4096, 1000)\n",
        "\n",
        "    def forward(self, x, training=True):\n",
        "        x = F.relu(self.layer1_1(x))\n",
        "        x = F.relu(self.layer1_2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.layer2_1(x))\n",
        "        x = F.relu(self.layer2_2(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.layer3_1(x))\n",
        "        x = F.relu(self.layer3_2(x))\n",
        "        x = F.relu(self.layer3_3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.layer4_1(x))\n",
        "        x = F.relu(self.layer4_2(x))\n",
        "        x = F.relu(self.layer4_3(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.layer5_1(x))\n",
        "        x = F.relu(self.layer5_2(x))\n",
        "        x = F.relu(self.layer5_3(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 7 * 7 * 512)\n",
        "        x = F.relu(self.fully_connected6(x))\n",
        "        x = F.dropout(x, 0.5, training=training)\n",
        "        x = F.relu(self.fully_connected7(x))\n",
        "        x = F.dropout(x, 0.5, training=training)\n",
        "        x = self.fully_connected8(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    # Fully Connected layers\n",
        "    self.layer6 = vgg_fc_layer(7*7*512, 4096)\n",
        "    self.layer7 = vgg_fc_layer(4096, 4096)\n",
        "\n",
        "    # Final layer\n",
        "    self.layer8 = nn.Linear(4096, num_classes)"
      ],
      "metadata": {
        "id": "kMRgv80K6zMd"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(self, x):\n",
        "        # a function to predict the labels of a batch of inputs\n",
        "        x = F.softmax(self.forward(x, training=False))\n",
        "        return x    "
      ],
      "metadata": {
        "id": "AGZY93gaWavm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(self, x, y):\n",
        "        prediction = self.predict(x)\n",
        "        maxs, indices = torch.max(prediction, 1)\n",
        "        acc = 100 * torch.sum(torch.eq(indices.float(), y.float()).float())/y.size()[0]\n",
        "        return acc.cpu().data[0]\n"
      ],
      "metadata": {
        "id": "Iwy1fDcKWbBF"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = VGG_architecture(in_channels=3, num_classes=len(labels)).to(device)\n",
        "rate = nn.CrossEntropyLoss()\n",
        "learn_speed = 0.01\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learn_speed)\n",
        "total_steps = len(trainloader)\n",
        "number_of_epochs = 1"
      ],
      "metadata": {
        "id": "lTD0AEiwXNli"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(number_of_epochs):\n",
        "    for i, (images, category) in enumerate(trainloader):\n",
        "      __,outputs = model(images)\n",
        "      loss = rate(outputs, category )\n",
        "      print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, number_of_epochs, i+1, total_steps, loss.item()))\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_w9bBmUXTZY",
        "outputId": "8fe10983-9586-4b59-a394-440aac2c2f46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Step [1/390], Loss: 2.7814\n",
            "Epoch [1/1], Step [2/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [3/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [4/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [5/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [6/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [7/390], Loss: 0.0000\n",
            "Epoch [1/1], Step [8/390], Loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5QHvf22Fazj6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}